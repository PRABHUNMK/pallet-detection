{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\Prabhu/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2023-6-16 Python-3.10.4 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n",
      "YOLOv5  2023-6-16 Python-3.10.4 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 480x640 1 UP\n",
      "Speed: 10.5ms pre-process, 762.8ms inference, 1.0ms NMS per image at shape (1, 3, 480, 640)\n",
      "image 1/1: 480x640 2 Ps, 1 UP\n",
      "Speed: 14.6ms pre-process, 853.6ms inference, 3.5ms NMS per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'adaptiveThreshold'\n> Overload resolution failed:\n>  - adaptiveThreshold() missing required argument 'blockSize' (pos 5)\n>  - adaptiveThreshold() missing required argument 'blockSize' (pos 5)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Prabhu\\Desktop\\pallet-detection-maxbyte\\deep-learning\\final.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prabhu/Desktop/pallet-detection-maxbyte/deep-learning/final.ipynb#W0sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(bbox_region, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prabhu/Desktop/pallet-detection-maxbyte/deep-learning/final.ipynb#W0sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m# Threshold the grayscale image to create a binary mask\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Prabhu/Desktop/pallet-detection-maxbyte/deep-learning/final.ipynb#W0sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m threshvalue, thresh \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49madaptiveThreshold(gray, \u001b[39m0\u001b[39;49m, \u001b[39m255\u001b[39;49m, cv2\u001b[39m.\u001b[39;49mTHRESH_TOZERO_INV \u001b[39m+\u001b[39;49m cv2\u001b[39m.\u001b[39;49mTHRESH_OTSU)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prabhu/Desktop/pallet-detection-maxbyte/deep-learning/final.ipynb#W0sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39m#adaptive_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prabhu/Desktop/pallet-detection-maxbyte/deep-learning/final.ipynb#W0sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39m#print(threshvalue)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prabhu/Desktop/pallet-detection-maxbyte/deep-learning/final.ipynb#W0sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prabhu/Desktop/pallet-detection-maxbyte/deep-learning/final.ipynb#W0sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39m# Find contours in the binary mask\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Prabhu/Desktop/pallet-detection-maxbyte/deep-learning/final.ipynb#W0sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m contours, contvalue \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mfindContours(thresh, cv2\u001b[39m.\u001b[39mRETR_EXTERNAL, cv2\u001b[39m.\u001b[39mCHAIN_APPROX_SIMPLE)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'adaptiveThreshold'\n> Overload resolution failed:\n>  - adaptiveThreshold() missing required argument 'blockSize' (pos 5)\n>  - adaptiveThreshold() missing required argument 'blockSize' (pos 5)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "# Load the YOLOv5 model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', 'best_upp(11).pt', force_reload=True)\n",
    "model = torch.hub.load('yolov5', 'custom', 'best_upp(11).pt', source='local')\n",
    "model.to(device).eval()\n",
    "\n",
    "# Set camera parameters\n",
    "width, height = 640, 480  # Set the desired frame size\n",
    "fps = 30  # Set the desired frame rate\n",
    "\n",
    "# def calculate_image_centroid(start_x, start_y, end_x, end_y):\n",
    "#     width = end_x - start_x\n",
    "#     height = end_y - start_y\n",
    "#     centroid_x = start_x + (width / 2)\n",
    "#     centroid_y = start_y + (height / 2)\n",
    "#     return centroid_x, centroid_y\n",
    "def calculate_box_dimensions(xyxy):\n",
    "    x1, y1, x2, y2 = xyxy\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "    return width, height\n",
    "# Initialize the RealSense camera\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, fps)\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "# Start the camera stream\n",
    "pipeline.start(config)\n",
    "\n",
    "# Object detection loop\n",
    "while True:\n",
    "    # Wait for a new frame\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    color_frame = frames.get_color_frame()\n",
    "    depth_frame = frames.get_depth_frame()\n",
    "\n",
    "    # Convert the frame to a numpy array\n",
    "    frame = np.asanyarray(color_frame.get_data())\n",
    "    d_frame = np.asanyarray(depth_frame.get_data())\n",
    "\n",
    "    # Perform object detection\n",
    "    results = model(frame)\n",
    "    print(results)\n",
    "    # Display the results\n",
    "    for result in results.xyxy[0]:\n",
    "        if result is not None:\n",
    "            xyxy = result[:4].tolist()\n",
    "            conf = result[4].item()\n",
    "            cls = int(result[5].item())\n",
    "            box_width, box_height = calculate_box_dimensions(xyxy)\n",
    "            #print(f\"Width: {box_width}, Height: {box_height}\")\n",
    "                    \n",
    "\n",
    "            # Only draw bounding box and label if confidence is greater than 0.7\n",
    "            if conf > 0.5:\n",
    "                # Draw bounding box and label on the frame\n",
    "                if cls == 0 and box_width >=150 and box_height >=50 and box_height <=200 :\n",
    "                    cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3])), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f'W: {box_width}', (int(xyxy[2]), int(xyxy[3]) + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "                    cv2.putText(frame, f'H: {box_height}', (int(xyxy[2]), int(xyxy[3]) + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "                    start_x = int(xyxy[0])\n",
    "                    start_y = int(xyxy[1])\n",
    "                    end_x = int(xyxy[2])\n",
    "                    end_y = int(xyxy[3])\n",
    "\n",
    "                    # Extract the bounding box region\n",
    "                    bbox_region = frame[start_y:end_y, start_x:end_x]\n",
    "\n",
    "                    # Convert the region to grayscale\n",
    "                    gray = cv2.cvtColor(bbox_region, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Threshold the grayscale image to create a binary mask\n",
    "                    threshvalue, thresh = cv2.Threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                    #adaptive_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "                    #print(threshvalue)\n",
    "\n",
    "                    # Find contours in the binary mask\n",
    "                    contours, contvalue = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    print(contvalue)\n",
    "                \n",
    "    #                 cnt = contours[0]\n",
    "    #                 cnts = cnt + np.array([start_x, start_y])\n",
    "    # #                 cv2.drawContours(frame, [cnts], -1, (0,255,0), 3)\n",
    "    #                 epsilon = 0.05*cv2.arcLength(cnts,True)\n",
    "    #                 approx = cv2.approxPolyDP(cnts,epsilon,True)\n",
    "    #                 cv2.drawContours(frame, [approx], -1, (0,255,0), 3)\n",
    "\n",
    "                # Draw the contours on the frame within the bounding box region\n",
    "                    for contour in contours:\n",
    "                        \n",
    "                        contour = contour + np.array([start_x, start_y])\n",
    "    #                     x,y,w,h = cv2.boundingRect(contour)\n",
    "    #                     cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                        # Shift the contour points\n",
    "                        epsilon = 0.04*cv2.arcLength(contour,True)\n",
    "                        approx = cv2.approxPolyDP(contour,epsilon,True)\n",
    "                        cv2.drawContours(frame, [approx], -1, (0,255,0), 3)\n",
    "                        # leftmost = tuple(contour[contour[:,:,0].argmin()][0])\n",
    "                        # rightmost = tuple(contour[contour[:,:,0].argmax()][0])\n",
    "                        # topmost = tuple(contour[contour[:,:,1].argmin()][0])\n",
    "                        # bottommost = tuple(contour[contour[:,:,1].argmax()][0])\n",
    "                        # cv2.circle(frame, leftmost, 5, (255, 0, 0), -1)\n",
    "                        # cv2.circle(frame, rightmost, 5, (0, 0, 255), -1)\n",
    "                        # cv2.circle(frame, topmost, 5, (0, 255, 0), -1)\n",
    "                        # cv2.circle(frame, bottommost, 5, (0, 255, 0), -1)\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    if cls == 1 and box_width >=150 and box_height >=50 and box_height <=200 :\n",
    "                        cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3])), (0, 0, 255), 2)\n",
    "                    \n",
    "                #cv2.putText(frame, f'{conf}', (int(xyxy[0]), int(xyxy[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "#                 cv2.putText(frame, f'{cls}', (int(xyxy[0])+10, int(xyxy[1]) + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "                \n",
    "               \n",
    "                # cv2.putText(frame, f'{cls}', (int(xyxy[2]+10), int(xyxy[3]) + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "                \n",
    "    # Display the frame\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Stop the camera stream\n",
    "pipeline.stop()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
